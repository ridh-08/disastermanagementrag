{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyNH4E91ZcY+t6+z8mFfQvry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridh-08/disastermanagementrag/blob/main/promptengineeringrag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlgZLUtUB1m_"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Install packages\n",
        "!pip install python-docx scikit-learn requests ipywidgets fpdf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Upload documents\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "U-k3Rcc_4yf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Imports and Setup\n",
        "import requests, json\n",
        "from docx import Document\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Configure Gemini\n",
        "GEMINI_API_KEY = \"AIzaSyBVESVD2g6qJvDiIcS5BkQahqwNHanKh0E\"\n",
        "API_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent?key={GEMINI_API_KEY}\"\n",
        "\n",
        "# Store outputs here\n",
        "outputs = {}\n"
      ],
      "metadata": {
        "id": "aF-PyPfi5BN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Define the prompt options\n",
        "prompt_options = {\n",
        "    \"Activity 1 – Identify Common Policies\": (\n",
        "        \"Implement a Prompt Chain to identify common AI-generated policy recommendations for earthquake and wildfire preparedness in India, \"\n",
        "        \"using policies from provided documents (‘Earthquake Final Policies.docx’ and ‘Policy Recommendations for Wildfires.docx’). \"\n",
        "        \"Follow this step-by-step implementation process: Task Decomposition: Break down the task of identifying common policy recommendations into sub-tasks: \"\n",
        "        \"(a) Summarize earthquake policies, (b) Summarize wildfire policies, (c) Compare for overlaps, (d) Categorize commonalities, and (e) Refine for India’s context. \"\n",
        "        \"Use AI to brainstorm sub-task clarity, ensuring alignment with document policies like ‘Urban Evacuation Micro-Zoning’ (earthquake) and ‘Decentralized Alert System’ (wildfire). \"\n",
        "        \"Node Creation: Formulate natural language prompts for each sub-task: Node 1: ‘List earthquake policies from the document, such as “Multi-Tiered Alert Framework” and “CBEP,” noting prevention and response elements for urban/rural India.’ \"\n",
        "        \"Node 2: ‘List wildfire policies, like “VFFCs” and “Pine Needle Management,” detailing prevention and response for forest/rural areas.’ \"\n",
        "        \"Node 3: ‘Compare earthquake and wildfire policies to identify shared themes, like alert systems or community roles, referencing document rationales (e.g., “life-saving potential”).’ \"\n",
        "        \"Node 4: ‘Categorize common policies into themes (e.g., tech, governance), ensuring relevance to India’s disaster landscape.’ \"\n",
        "        \"Node 5: ‘Refine common policies, suggesting enhancements like offline alerts for rural gaps, based on document insights.’ \"\n",
        "        \"Node Connection: Validate logical connections between nodes to ensure flow: Node 1 and 2 outputs feed Node 3 for comparison, Node 3 informs Node 4’s categorization, and Node 4 guides Node 5’s refinement. \"\n",
        "        \"Use AI to check if connections align (e.g., does ‘UDNS’ link to ‘SMS Alerts’ logically?). Chain Refinement: Analyze initial outputs for completeness, identifying gaps (e.g., missing urban wildfire policies) or redundancies. \"\n",
        "        \"Use AI to suggest refinements, such as merging similar alert policies or adding urban buffer zones for wildfires, drawing on document best practices (e.g., Tokyo’s mapping, Indonesia’s Destana). \"\n",
        "        \"User  Feedback Integration: Structure a feedback mechanism to validate outputs, such as a checklist for policy relevance (e.g., ‘Does it address rural India?’). \"\n",
        "        \"Use AI to analyze feedback and adjust the chain, ensuring the final output is a table of 5–10 common policies (e.g., early warning, community training), with stakeholders, themes, and India-specific adaptations, incorporating document specifics like ‘EPI’ or ‘MGNREGA links.’\"\n",
        "    ),\n",
        "    \"Activity 2 – Evaluate Region-Specific vs. Generalizable Policies\": (\n",
        "        \"Visualize a team of three world-class disaster policy experts—a policy analyst, a field-level emergency responder, and a technology and infrastructure planner—collaboratively evaluating the adaptability of an AI-generated disaster response policy. \"\n",
        "        \"They will follow the Tree of Thoughts approach, where each expert shares their step-by-step reasoning, openly acknowledges uncertainties, corrects assumptions, and builds upon each other’s perspectives. \"\n",
        "        \"Their goal is to determine whether the given policy is region-specific or generalizable across different Indian disaster contexts. \"\n",
        "        \"In their discussion, they will organically explore the following: The Five Ws and How: Who benefits from the policy? What are the policy’s core components? When is it most effective (timing, seasonal or urgency conditions)? \"\n",
        "        \"Where can it realistically be implemented, and where not? Why might it fail in certain geographies? How can it be adapted or scaled? The PESTEL framework for context evaluation: Political feasibility in different states, \"\n",
        "        \"Economic viability in low-resource areas, Social acceptance across rural/urban communities, Technological infrastructure needs, Environmental constraints (e.g., terrain, vegetation), Legal-institutional alignment with disaster laws or local governance. \"\n",
        "        \"The team will refine the policy iteratively, flag limitations, propose alternate implementations, and conclude whether the strategy is scalable or requires regional tailoring. \"\n",
        "        \"Illustrate the entire dialogue in a markdown table, where each row contains the expert’s name, their step in the reasoning tree, and their evolving insights. \"\n",
        "        \"The policies being evaluated are in the documents attached. Ensure the discussion reaches a clear conclusion, but the process should reflect critical back-and-forth reasoning and real-world grounding. \"\n",
        "        \"Prioritize accuracy and precision in your responses. Avoid speculation, assumptions, and any form of extrapolation that might lead to incorrect or misleading information.\"\n",
        "    ),\n",
        "    \"Activity 3 – Assess AI’s Strengths & Limitations\": (\n",
        "        \"Act as a world-class information verifier and Generative AI content generation refinement agent to assess AI’s strengths and limitations in generating earthquake and wildfire policies for India, based on provided documents (‘Earthquake Final Policies.docx’ and ‘Policy Recommendations for Wildfires.docx’). \"\n",
        "        \"Follow this integrated process: Phase 1: Chain of Verification Act as a world-class information verifier to generate an initial assessment: Propose strengths, such as integrating GIS in ‘Urban Evacuation Micro-Zoning’ or enabling inclusive alerts in ‘Decentralized Alert System,’ and limitations, like offline gaps in ‘Vulnerable Population Registry’ or cultural training needs in ‘Pine Needle Cooperatives.’ \"\n",
        "        \"Review your response and highlight key points needing verification, like ‘AI scales policies to 600 districts’ or ‘AI misses rural offline contexts.’ Generate specific verification questions, such as ‘Can AI scale “UDNS” SMS alerts nationally per document’s low-cost rationale?’ or ‘Does AI address Uttarakhand’s training gaps for “VFFCs” per MGNREGA links?’ \"\n",
        "        \"Address each question separately, using evidence from document policies (e.g., earthquake’s ‘IVR backups,’ wildfire’s ‘community radios’) or global best practices (e.g., Tokyo’s micro-mapping, Indonesia’s Destana). \"\n",
        "        \"Modify your initial response based on verification results, detailing changes (e.g., qualifying scalability for rural areas). Please note: Share both the verification questions and their answers, detail any changes made to the original response, and make autonomous adjustments to ensure accuracy. \"\n",
        "        \"Output a validated pros-cons list as the interim assessment, incorporating document specifics like ‘Evacuation Preparedness Index’ or ‘parali bans.’ Phase 2: Automated Output Refinement Act as my Generative AI content generation refinement agent to refine the validated pros-cons list: \"\n",
        "        \"Use the interim pros-cons list from Phase 1 as the initial content. Conduct a focused critique on how to enhance the content. Be rigorous, flagging issues like vague claims (e.g., ‘AI is inclusive’ without specifics), urban bias (e.g., overemphasizing micro-zoning), or lack of conciseness, even if the content seems acceptable. \"\n",
        "        \"Generate refined content based on your critique, improving clarity, specificity, and actionability (e.g., refining ‘AI scales well’ to ‘AI scales SMS alerts but needs offline radio training’). \"\n",
        "        \"Run the refinement iteration three times, each time critiquing and enhancing the previous output, ensuring alignment with document metrics (e.g., ‘low-cost,’ ‘life-saving potential’) and India’s urban-rural context. \"\n",
        "        \"Output the final refined pros-cons list after three iterations, detailing each critique and improvement made, ensuring the assessment is precise, evidence-based, and tailored to India’s disaster policy making context. Include a summary table with columns: Strength/Limitation, Description, Document Evidence, Refinement Notes.\"\n",
        "    ),\n",
        "    \"Activity 4 – Score & Rank Policies\": (\n",
        "        \"Step 1: Self-Consistency Sub-Prompt 1 - Urban Effectiveness Purpose: Generate initial scores for earthquake and wildfire policies focusing on urban effectiveness, prioritizing metrics like evacuation speed or fire suppression impact. \"\n",
        "        \"Prompt: Score AI-generated earthquake and wildfire policies from provided documents (‘Earthquake Final Policies.docx’ and ‘Policy Recommendations for Wildfires.docx’) for urban effectiveness, prioritizing metrics like evacuation speed, fire suppression impact, or lives saved. \"\n",
        "        \"Include policies such as ‘Urban Evacuation Micro-Zoning’ and ‘Unified Disaster Notification System’ (earthquake), and ‘Decentralized Alert System’ and ‘Parali Ban’ (wildfire). Assign numerical scores (1–10) for each policy based on their impact in urban India, referencing document specifics like ‘SMS alerts’ or ‘GIS dashboards.’ \"\n",
        "        \"Output a table with columns: Policy Name, Effectiveness Score, Rationale, ensuring alignment with India’s urban context. Step 2: Self-Consistency Sub-Prompt 2 - Rural Feasibility Purpose: Generate scores for earthquake and wildfire policies focusing on rural feasibility, emphasizing metrics like cost and infrastructure constraints. \"\n",
        "        \"Prompt: Score AI-generated earthquake and wildfire policies from provided documents (‘Earthquake Final Policies.docx’ and ‘Policy Recommendations for Wildfires.docx’) for rural feasibility, emphasizing metrics like cost, infrastructure availability, and community adoption in rural India. \"\n",
        "        \"Include policies such as ‘Community-Based Evacuation Planning’ and ‘Vulnerable Population Registry’ (earthquake), and ‘Village Fire Committees’ and ‘Pine Needle Management’ (wildfire). Assign numerical scores (1–10) for each policy based on their practicality in rural settings, referencing document specifics like ‘low-cost loudspeakers,’ ‘MGNREGA links,’ or ‘Gram Panchayat mapping.’ Output a table with columns: Policy Name, Feasibility Score, Rationale, ensuring alignment with India’s rural context. Step 3: Self-Consistency Sub-Prompt 3 - National Scalability Purpose: Generate scores for earthquake and wildfire policies focusing on national scalability, assessing their applicability across India’s diverse states. Prompt: Score AI-generated earthquake and wildfire policies from provided documents (‘Earthquake Final Policies.docx’ and ‘Policy Recommendations for Wildfires.docx’) for national scalability, assessing their applicability across India’s states, prioritizing metrics like stakeholder coordination, tech infrastructure, and regional adaptability. Include policies such as ‘Evacuation Preparedness Index’ and ‘Multi-Tiered Alert Framework’ (earthquake), and ‘Village Fire Committees’ and ‘Decentralized Alert System’ (wildfire). Assign numerical scores (1–10) for each policy based on their potential to scale nationwide, referencing document specifics like ‘Smart Cities funding,’ ‘SMS alerts,’ or ‘scalable nationwide’ claims. Output a table with columns: Policy Name, Scalability Score, Rationale, ensuring alignment with India’s diverse urban-rural and regional context. Step 4: Self-Consistency - Consistency Evaluation Purpose: Analyze the three sets of scores (urban effectiveness, rural feasibility, national scalability) for coherence, identifying consistent patterns and resolving outliers to prepare for verification. Prompt: Analyze the three sets of scores for AI-generated earthquake and wildfire policies from provided documents (‘Earthquake Final Policies.docx’ and ‘Policy Recommendations for Wildfires.docx’), previously generated for urban effectiveness, rural feasibility, and national scalability. Include policies like ‘Unified Disaster Notification System’ and ‘Evacuation Preparedness Index’ (earthquake), and ‘Decentralized Alert System’ and ‘Village Fire Committees’ (wildfire). Follow these steps: 1) Compare scores across the three dimensions to identify patterns (e.g., policies scoring consistently high, like ‘UDNS’ for effectiveness and scalability). 2) Flag outliers (e.g., a policy scoring high for urban effectiveness but low for rural feasibility, such as ‘Urban Evacuation Micro-Zoning’). 3) Propose adjustments for outliers, justifying with document specifics (e.g., ‘low-cost SMS’ for scalability, ‘rural tech gaps’ for feasibility). Output a table with columns: Policy Name, Urban Effectiveness Score, Rural Feasibility Score, Scalability Score, Consistency Notes, and Proposed Adjustments, ensuring alignment with India’s urban-rural and regional context. Step 5: Chain of Verification - Score Validation Purpose: Validate the adjusted scores from the consistency evaluation by generating questions, answering them with document evidence, and refining scores to ensure accuracy. Prompt: Act as a world-class information verifier to validate the adjusted scores for AI-generated earthquake and wildfire policies from provided documents (‘Earthquake Final Policies.docx’ and ‘Policy Recommendations for Wildfires.docx’), based on the consistency evaluation of urban effectiveness, rural feasibility, and national scalability. Include policies like ‘Unified Disaster Notification System’ and ‘Evacuation Preparedness Index’ (earthquake), and ‘Decentralized Alert System’ and ‘Village Fire Committees’ (wildfire). Follow this verification process: Review the adjusted scores and highlight key points needing verification, such as ‘“UDNS” scores 8/10 for scalability’ or ‘“VFFCs” scores 6/10 for feasibility.’ Generate specific verification questions, like ‘Does “UDNS” scalability align with the document’s claim of 600-district SMS coverage?’ or ‘Is “VFFCs” feasibility limited by rural training gaps per MGNREGA evidence?’ Answer each question separately, using evidence from document policies (e.g., earthquake’s ‘IVR backups,’ wildfire’s ‘community radios’) or global best practices (e.g., Indonesia’s Destana village planning, Tokyo’s micro-mapping). Modify scores based on verification results, detailing changes (e.g., ‘Lower “Pine Cooperatives” feasibility due to regional training limits’). Share both the verification questions and their answers, detail all changes made, and make autonomous adjustments for accuracy. Output a revised table with columns: Policy Name, Urban Effectiveness Score, Rural Feasibility Score, Scalability Score, Verification Notes, ensuring alignment with India’s disaster policymaking context. Step 6: Final Synthesis and Output Purpose: Synthesize the verified scores from the consistency evaluation and verification steps into a prioritized ranking of earthquake and wildfire policies, ensuring a reliable and evidence-based final output. Prompt: Synthesize the verified scores for AI-generated earthquake and wildfire policies from provided documents (‘Earthquake Final Policies.docx’ and ‘Policy Recommendations for Wildfires.docx’), based on the consistency evaluation and verification outputs for urban effectiveness, rural feasibility, and national scalability. Include policies like ‘Unified Disaster Notification System’ and ‘Evacuation Preparedness Index\"\n",
        "    )\n",
        "}\n",
        "\n",
        "prompt_dropdown = widgets.Dropdown(\n",
        "    options=prompt_options,\n",
        "    description='Select Prompt:',\n",
        "    layout=widgets.Layout(width='95%')\n",
        ")\n",
        "\n",
        "display(prompt_dropdown)"
      ],
      "metadata": {
        "id": "q7BfFD7W5Ilp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: Load and chunk documents\n",
        "def extract_text(path):\n",
        "    doc = Document(path)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
        "\n",
        "wildfire_text = extract_text(\"Policy Recommendations for Wildfires.docx\")\n",
        "earthquake_text = extract_text(\"Earthquake Final Policies.docx\")\n",
        "combined_text = wildfire_text + \"\\n\" + earthquake_text\n",
        "\n",
        "def chunk_text(text, chunk_size=1000, overlap=200):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        chunks.append(\" \".join(words[i:i + chunk_size]))\n",
        "        i += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(combined_text)\n"
      ],
      "metadata": {
        "id": "E-JsJKfh5N04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Retrieve context using TF-IDF\n",
        "def retrieve_context(question, k=3):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    chunk_vectors = vectorizer.fit_transform(chunks)\n",
        "    query_vec = vectorizer.transform([question])\n",
        "    similarities = cosine_similarity(query_vec, chunk_vectors).flatten()\n",
        "    top_indices = similarities.argsort()[-k:][::-1]\n",
        "    return \"\\n\\n\".join([chunks[i] for i in top_indices])\n"
      ],
      "metadata": {
        "id": "i7zFFcZ_8Ns8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: Ask Gemini with extended token support\n",
        "def ask_gemini(prompt_text, context):\n",
        "    full_prompt = f\"\"\"Use the following context to perform the analysis task below:\n",
        "\n",
        "{prompt_text}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\"text\": full_prompt}]\n",
        "        }],\n",
        "        \"generationConfig\": {\n",
        "            \"maxOutputTokens\": 32768\n",
        "        }\n",
        "    }\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        return result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "    else:\n",
        "        return f\"Error {response.status_code}: {response.text}\"\n"
      ],
      "metadata": {
        "id": "ANJxHcwc8R7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: Run selected prompt\n",
        "selected_prompt = prompt_dropdown.label\n",
        "context = retrieve_context(prompt_dropdown.value)\n",
        "response_text = ask_gemini(prompt_dropdown.value, context)\n",
        "\n",
        "outputs[selected_prompt] = response_text\n",
        "\n",
        "print(f\"\\n=== Gemini Output for {selected_prompt} ===\\n\")\n",
        "print(response_text)\n"
      ],
      "metadata": {
        "id": "F-3b42B08ZU6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}